{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Qp0H_zUQuu_"
   },
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[HSE][ML][HW05] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "22ezVRf3QuvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from typing import List, NoReturn\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qfDPH_LQuvF"
   },
   "source": [
    "### Задание 1 (3 балла)\n",
    "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
    "\n",
    "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
    "\n",
    "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
    "\n",
    "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
    "\n",
    "\n",
    "#### Методы\n",
    "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
    "\n",
    "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
    "\n",
    "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RWFLlHqaYbgC"
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    \"\"\"\n",
    "    Абстрактный класс. Его менять не нужно.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def backward(self, d):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def update(self, alpha):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aYS2gE4PYepZ"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \"\"\"\n",
    "    Линейный полносвязный слой.\n",
    "    \"\"\"\n",
    "    W = None\n",
    "    b = None\n",
    "    in_features = None\n",
    "    out_features = None\n",
    "    x = None\n",
    "    \n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_features : int\n",
    "            Размер входа.\n",
    "        out_features : int \n",
    "            Размер выхода.\n",
    "    \n",
    "        Notes\n",
    "        -----\n",
    "        W и b инициализируются случайно.\n",
    "        \"\"\"\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        n = out_features + in_features\n",
    "        \n",
    "        self.W = np.random.uniform( -(sqrt(6.0) / sqrt(n)), (sqrt(6.0) / sqrt(n)), [out_features, in_features])\n",
    "        self.b = np.random.uniform( -(sqrt(6.0) / sqrt(n)), (sqrt(6.0) / sqrt(n)), [out_features])\n",
    "            \n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Возвращает y = Wx + b.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Входной вектор или батч.\n",
    "            То есть, либо x вектор с in_features элементов,\n",
    "            либо матрица размерности (batch_size, in_features).\n",
    "    \n",
    "        Return\n",
    "        ------\n",
    "        y : np.ndarray\n",
    "            Выход после слоя.\n",
    "            Либо вектор с out_features элементами,\n",
    "            либо матрица размерности (batch_size, out_features)\n",
    "\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        return x @ self.W.T + self.b\n",
    "    \n",
    "    def backward(self, d: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Cчитает градиент при помощи обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : np.ndarray\n",
    "            Градиент.\n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Новое значение градиента.\n",
    "        \"\"\"\n",
    "        self.d = d\n",
    "        return d @ self.W\n",
    "        \n",
    "    def update(self, alpha: float) -> NoReturn:\n",
    "        \"\"\"\n",
    "        Обновляет W и b с заданной скоростью обучения.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha : float\n",
    "            Скорость обучения.\n",
    "        \"\"\"\n",
    "        self.b = self.b - alpha * np.sum(self.d, axis=0)\n",
    "        \n",
    "        self.W = self.W - alpha * (self.d.T @ self.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "94hkbnD1QuvG"
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    x = None\n",
    "    \"\"\"\n",
    "    Слой, соответствующий функции активации ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Возвращает y = max(0, x).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Входной вектор или батч.\n",
    "    \n",
    "        Return\n",
    "        ------\n",
    "        y : np.ndarray\n",
    "            Выход после слоя (той же размерности, что и вход).\n",
    "\n",
    "        \"\"\"\n",
    "       \n",
    "        self.x = x\n",
    "        return np.maximum(x, 0)\n",
    "        \n",
    "    def backward(self, d) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Cчитает градиент при помощи обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : np.ndarray\n",
    "            Градиент.\n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Новое значение градиента.\n",
    "        \"\"\"\n",
    "        tmp = np.where(self.x < 0, 0, self.x)\n",
    "        tmp = np.where(tmp > 0, 1, tmp)\n",
    "        return d * tmp\n",
    "        \n",
    "        \n",
    "class Softmax(Module):\n",
    "    \"\"\"\n",
    "    Слой, соответствующий функции активации Softmax.\n",
    "    \"\"\"\n",
    "    x = None\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Возвращает y = Softmax(x).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Входной вектор или батч.\n",
    "    \n",
    "        Return\n",
    "        ------\n",
    "        y : np.ndarray\n",
    "            Выход после слоя (той же размерности, что и вход).\n",
    "\n",
    "        \"\"\"\n",
    "        self.x = np.exp(x) / np.array([np.exp(x).sum(axis = 1)] * x.shape[1]).T\n",
    "        return self.x\n",
    "        \n",
    "    def backward(self, d) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Cчитает градиент при помощи обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : np.ndarray\n",
    "            Градиент.\n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Новое значение градиента.\n",
    "        \"\"\"\n",
    "        return self.x - d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb_ip_h8QuvJ"
   },
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь сделаем саму нейронную сеть.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
    "\n",
    "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
    "\n",
    "`epochs` - количество эпох обучения\n",
    "\n",
    "`alpha` - скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q_JFCizKQuvK"
   },
   "outputs": [],
   "source": [
    "class MLPClassifier:\n",
    "    modules = None\n",
    "    epochs = None\n",
    "    alpha = None\n",
    "    class_num = None\n",
    "    def __init__(self, modules: List[Module], epochs: int = 40, alpha: float = 0.001):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        modules : List[Module]\n",
    "            Cписок, состоящий из ранее реализованных модулей и \n",
    "            описывающий слои нейронной сети. \n",
    "            В конец необходимо добавить Softmax.\n",
    "        epochs : int\n",
    "            Количество эпох обученияю\n",
    "        alpha : float\n",
    "            Cкорость обучения.\n",
    "        \"\"\"\n",
    "        self.modules = modules + [Softmax()]\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "            \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, batch_size=32) -> NoReturn:\n",
    "        \"\"\"\n",
    "        Обучает нейронную сеть заданное число эпох. \n",
    "        В каждой эпохе необходимо использовать cross-entropy loss для обучения, \n",
    "        а так же производить обновления не по одному элементу, а используя батчи.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Данные для обучения.\n",
    "        y : np.ndarray\n",
    "            Вектор меток классов для данных.\n",
    "        batch_size : int\n",
    "            Размер батча.\n",
    "        \"\"\"\n",
    "        self.class_num = len(np.unique(y))\n",
    "        for epoch in range(0, self.epochs):\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                tmp_x = X[i:(i+batch_size)]\n",
    "                tmp_y = np.array([[0] * self.class_num] * len(tmp_x))\n",
    "                for j in range(0, len(tmp_y)):\n",
    "                    tmp_y[j][y[i + j]] = 1\n",
    "                    \n",
    "                for module in self.modules:\n",
    "                    tmp_x = module.forward(tmp_x)\n",
    "                \n",
    "                \n",
    "                for j, module in enumerate(self.modules[::-1]):\n",
    "                    tmp_y = module.backward(tmp_y)\n",
    "                    if j % 2 != 0:\n",
    "                        module.update(self.alpha)\n",
    "                \n",
    "            \n",
    "        \n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Предсказывает вероятности классов для элементов X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Данные для предсказания.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Предсказанные вероятности классов для всех элементов X.\n",
    "            Размерность (X.shape[0], n_classes)\n",
    "        \n",
    "        \"\"\"\n",
    "        ans = np.zeros((X.shape[0], self.class_num))\n",
    "        for i, x in enumerate(X):\n",
    "            tmp_x = np.array([x])\n",
    "            for j, module in enumerate(self.modules):\n",
    "                tmp_x = module.forward(tmp_x)\n",
    "            ans[i] = tmp_x\n",
    "        return ans\n",
    "        \n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Предсказывает метки классов для элементов X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Данные для предсказания.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Вектор предсказанных классов\n",
    "        \n",
    "        \"\"\"\n",
    "        p = self.predict_proba(X)\n",
    "        return np.argmax(p, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "onDymYQXQuvN"
   },
   "outputs": [],
   "source": [
    "p = MLPClassifier([\n",
    "    Linear(4, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 2)\n",
    "])\n",
    "\n",
    "X = np.random.randn(50, 4)\n",
    "y = [(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X]\n",
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C1EIsDqQuvQ"
   },
   "source": [
    "### Задание 3 (2 балла)\n",
    "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
    "\n",
    "#### Оценка\n",
    "Accuracy на первом датасете больше 0.85 - +1 балл\n",
    "\n",
    "Accuracy на втором датасете больше 0.85 - +1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d5UAgXTcQuvQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n",
      "Accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons(400, noise=0.075)\n",
    "X_test, y_test = make_moons(400, noise=0.075)\n",
    "print(X.shape)\n",
    "best_acc = 0\n",
    "for _ in range(25):\n",
    "    p = MLPClassifier([\n",
    "        Linear(2, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 2)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "    p.fit(X, y)\n",
    "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
    "print(\"Accuracy\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MMDJM4qFQuvT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.955\n"
     ]
    }
   ],
   "source": [
    "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "best_acc = 0\n",
    "for _ in range(25):\n",
    "    p = p = MLPClassifier([\n",
    "        Linear(2, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 3)\n",
    "    ])\n",
    "\n",
    "    p.fit(X, y)\n",
    "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
    "print(\"Accuracy\", best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPbVTFnMQuvW"
   },
   "source": [
    "## PyTorch\n",
    "\n",
    "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tV0mJLu-QuvX"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VUC_QqpAQuva"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357a47b007aa441eaf54def3c47a0690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/cifar10/cifar-10-python.tar.gz to datasets/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = transforms.ToTensor()\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
    "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
    "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGmpjcFfQuvd"
   },
   "source": [
    "### Задание 4 (3 балла)\n",
    "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
    "\n",
    "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
    "\n",
    "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
    "\n",
    "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5sRmTKwKQuve"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n",
    "    \"\"\"\n",
    "    Cчитает cross-entropy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : torch.Tensor\n",
    "        Данные для обучения.\n",
    "    y : torch.Tensor\n",
    "        Метки классов.\n",
    "    model : Model\n",
    "        Модель, которую будем обучать.\n",
    "\n",
    "    \"\"\"\n",
    "    prediction = model(X)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss(prediction, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAsLmkUqQuvh"
   },
   "source": [
    "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "k5G8iMCeQuvh"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in range(epochs):\n",
    "        #Train\n",
    "        loss_mean = 0\n",
    "        elements = 0\n",
    "        for X, y in iter(train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        train_losses.append(loss_mean / elements)\n",
    "        #Test\n",
    "        loss_mean = 0 \n",
    "        elements = 0\n",
    "        for X, y in iter(test_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        test_losses.append(loss_mean / elements)\n",
    "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "vmD9eWJOQuvl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss 2.1584290516662596 | Test loss 2.0071142459869384\n",
      "Epoch 1 | Train loss 1.9005691941833496 | Test loss 1.783334956741333\n",
      "Epoch 2 | Train loss 1.7498809079742432 | Test loss 1.7105054460525513\n",
      "Epoch 3 | Train loss 1.670283283882141 | Test loss 1.6523817167282104\n",
      "Epoch 4 | Train loss 1.629459761390686 | Test loss 1.6049561126708984\n",
      "Epoch 5 | Train loss 1.5910261946487427 | Test loss 1.5656414514541626\n",
      "Epoch 6 | Train loss 1.5563438565063477 | Test loss 1.5788633378982544\n",
      "Epoch 7 | Train loss 1.525462788772583 | Test loss 1.5158034156799316\n",
      "Epoch 8 | Train loss 1.4891276596450806 | Test loss 1.473026852607727\n",
      "Epoch 9 | Train loss 1.4567995728683472 | Test loss 1.4409708965301513\n",
      "Epoch 10 | Train loss 1.4288938187026978 | Test loss 1.437555672645569\n",
      "Epoch 11 | Train loss 1.408723664932251 | Test loss 1.4237150733947754\n",
      "Epoch 12 | Train loss 1.3854257103347778 | Test loss 1.3944596046447755\n",
      "Epoch 13 | Train loss 1.3662716019058228 | Test loss 1.3864581453323364\n",
      "Epoch 14 | Train loss 1.3424153329467774 | Test loss 1.3633033548355102\n",
      "Epoch 15 | Train loss 1.3218117447662354 | Test loss 1.3296160140991211\n",
      "Epoch 16 | Train loss 1.3118577104187013 | Test loss 1.3220175653457642\n",
      "Epoch 17 | Train loss 1.296953821105957 | Test loss 1.314034616470337\n",
      "Epoch 18 | Train loss 1.2833072653579711 | Test loss 1.316898204612732\n",
      "Epoch 19 | Train loss 1.2756725542449951 | Test loss 1.282743692779541\n",
      "Epoch 20 | Train loss 1.2555663446044922 | Test loss 1.2800864372253418\n",
      "Epoch 21 | Train loss 1.241950804901123 | Test loss 1.2667771047592162\n",
      "Epoch 22 | Train loss 1.2307429081726073 | Test loss 1.2768793048858642\n",
      "Epoch 23 | Train loss 1.2249777531433106 | Test loss 1.2489980024337768\n",
      "Epoch 24 | Train loss 1.2122842950820922 | Test loss 1.2648847883224488\n",
      "Epoch 25 | Train loss 1.205706216316223 | Test loss 1.2290412759780884\n",
      "Epoch 26 | Train loss 1.1906352633285522 | Test loss 1.239954757118225\n",
      "Epoch 27 | Train loss 1.183506294517517 | Test loss 1.2164639385223388\n",
      "Epoch 28 | Train loss 1.1740725968551635 | Test loss 1.2243352014541626\n",
      "Epoch 29 | Train loss 1.163924524040222 | Test loss 1.2185599325180054\n",
      "Epoch 30 | Train loss 1.1564695796203612 | Test loss 1.2218065029144287\n",
      "Epoch 31 | Train loss 1.1534983443069458 | Test loss 1.2148994920730591\n",
      "Epoch 32 | Train loss 1.139864649810791 | Test loss 1.2195058025360108\n",
      "Epoch 33 | Train loss 1.139011051826477 | Test loss 1.1831981828689575\n",
      "Epoch 34 | Train loss 1.1356851025390624 | Test loss 1.1894643754959107\n",
      "Epoch 35 | Train loss 1.1210897150421142 | Test loss 1.1736330326080322\n",
      "Epoch 36 | Train loss 1.1120711149215698 | Test loss 1.1760814786911011\n",
      "Epoch 37 | Train loss 1.1220803261184693 | Test loss 1.208445827293396\n",
      "Epoch 38 | Train loss 1.116874263458252 | Test loss 1.1698653388977052\n",
      "Epoch 39 | Train loss 1.0969841452407836 | Test loss 1.1512470848083496\n",
      "Epoch 40 | Train loss 1.0784725836181641 | Test loss 1.1621015031814574\n",
      "Epoch 41 | Train loss 1.077788455581665 | Test loss 1.1764452751159669\n",
      "Epoch 42 | Train loss 1.0761056924819947 | Test loss 1.1468767684936523\n",
      "Epoch 43 | Train loss 1.067605139427185 | Test loss 1.1413467819213867\n",
      "Epoch 44 | Train loss 1.0608530975723267 | Test loss 1.1417357879638672\n",
      "Epoch 45 | Train loss 1.0487409635543823 | Test loss 1.1583983007431031\n",
      "Epoch 46 | Train loss 1.0454882154083251 | Test loss 1.1395569150924683\n",
      "Epoch 47 | Train loss 1.0360320060539245 | Test loss 1.1203820976257324\n",
      "Epoch 48 | Train loss 1.0314858209991455 | Test loss 1.1376149059295655\n",
      "Epoch 49 | Train loss 1.0354949977874757 | Test loss 1.1373161352157592\n",
      "Epoch 50 | Train loss 1.029536441268921 | Test loss 1.1169756441116332\n",
      "Epoch 51 | Train loss 1.024926172027588 | Test loss 1.1176004722595214\n",
      "Epoch 52 | Train loss 1.017732315711975 | Test loss 1.1197597801208496\n",
      "Epoch 53 | Train loss 1.0112775101852416 | Test loss 1.1152197492599487\n",
      "Epoch 54 | Train loss 1.003186232662201 | Test loss 1.1113554904937744\n",
      "Epoch 55 | Train loss 0.9965887038612365 | Test loss 1.102318942642212\n",
      "Epoch 56 | Train loss 0.9930275458145141 | Test loss 1.111794693183899\n",
      "Epoch 57 | Train loss 0.9894674787902832 | Test loss 1.1071772428512574\n",
      "Epoch 58 | Train loss 0.98057098487854 | Test loss 1.0987737426757813\n",
      "Epoch 59 | Train loss 0.9789915725326538 | Test loss 1.1094708616256714\n",
      "Epoch 60 | Train loss 0.9819620096206665 | Test loss 1.0898578994750976\n",
      "Epoch 61 | Train loss 0.9752377476501465 | Test loss 1.1216153905868531\n",
      "Epoch 62 | Train loss 0.9689037013053894 | Test loss 1.0898439792633057\n",
      "Epoch 63 | Train loss 0.9614975566482544 | Test loss 1.0930006011962892\n",
      "Epoch 64 | Train loss 0.9613284065246582 | Test loss 1.1058919717788696\n",
      "Epoch 65 | Train loss 0.9546070446395875 | Test loss 1.0943601715087892\n",
      "Epoch 66 | Train loss 0.9458875993728638 | Test loss 1.1107816154479981\n",
      "Epoch 67 | Train loss 0.9555313307571411 | Test loss 1.1001995738983155\n",
      "Epoch 68 | Train loss 0.9404629720687866 | Test loss 1.082413914489746\n",
      "Epoch 69 | Train loss 0.9300099680519104 | Test loss 1.0937869178771973\n",
      "Epoch 70 | Train loss 0.9339854966163635 | Test loss 1.0919475732803345\n",
      "Epoch 71 | Train loss 0.9249624946594238 | Test loss 1.0771807041168213\n",
      "Epoch 72 | Train loss 0.9374168453788757 | Test loss 1.1125393392562866\n",
      "Epoch 73 | Train loss 0.9205736009407044 | Test loss 1.0875012245178222\n",
      "Epoch 74 | Train loss 0.9150600279617309 | Test loss 1.120182563018799\n",
      "Epoch 75 | Train loss 0.9226640306472779 | Test loss 1.0706103351593017\n",
      "Epoch 76 | Train loss 0.9136650264549255 | Test loss 1.0691472803115845\n",
      "Epoch 77 | Train loss 0.9154654258918762 | Test loss 1.0826135469436646\n",
      "Epoch 78 | Train loss 0.9072551315116882 | Test loss 1.0699295753479003\n",
      "Epoch 79 | Train loss 0.9023316358184814 | Test loss 1.0656162979125976\n",
      "Epoch 80 | Train loss 0.8992150610160827 | Test loss 1.0548596700668336\n",
      "Epoch 81 | Train loss 0.9027452198028565 | Test loss 1.0609879161834717\n",
      "Epoch 82 | Train loss 0.8870888358688355 | Test loss 1.0712854875564575\n",
      "Epoch 83 | Train loss 0.8800354166030884 | Test loss 1.063173094558716\n",
      "Epoch 84 | Train loss 0.880132921257019 | Test loss 1.0643835912704467\n",
      "Epoch 85 | Train loss 0.8822829663848877 | Test loss 1.0760130002975463\n",
      "Epoch 86 | Train loss 0.8744760021972656 | Test loss 1.068267781639099\n",
      "Epoch 87 | Train loss 0.8754822043800354 | Test loss 1.0710947292327881\n",
      "Epoch 88 | Train loss 0.8814325157928466 | Test loss 1.1001376424789429\n",
      "Epoch 89 | Train loss 0.8673576546859741 | Test loss 1.0622024627685547\n",
      "Epoch 90 | Train loss 0.8675249122047425 | Test loss 1.0768187232971191\n",
      "Epoch 91 | Train loss 0.8700834714317321 | Test loss 1.0691205068588256\n",
      "Epoch 92 | Train loss 0.8625738376235962 | Test loss 1.0641699863433838\n",
      "Epoch 93 | Train loss 0.8506248635292053 | Test loss 1.0729283243179322\n",
      "Epoch 94 | Train loss 0.8484197872924805 | Test loss 1.0639981662750244\n",
      "Epoch 95 | Train loss 0.8520728334617614 | Test loss 1.0856104969024658\n",
      "Epoch 96 | Train loss 0.8457185908699035 | Test loss 1.0756646257400513\n",
      "Epoch 97 | Train loss 0.839805016078949 | Test loss 1.0667037511825561\n",
      "Epoch 98 | Train loss 0.8424967334938049 | Test loss 1.058980601501465\n",
      "Epoch 99 | Train loss 0.8379824540710449 | Test loss 1.0750350538253783\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "train_l, test_l = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "F6OEGqriQuvo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
    "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miUxg0bDQuvs"
   },
   "source": [
    "И, наконец, посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "UXSOJFI8Quvt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy 0.6315\n",
      "Precision [0.67838676 0.77005348 0.5        0.40499307 0.62801378 0.5746988\n",
      " 0.79268293 0.69293756 0.66831683 0.75578704]\n",
      "Recall [0.656 0.72  0.541 0.584 0.547 0.477 0.65  0.677 0.81  0.653]\n",
      "Mean Precision 0.6465870236277225\n",
      "Mean Recall 0.6315000000000002\n"
     ]
    }
   ],
   "source": [
    "true_positive = np.zeros(10)\n",
    "true_negative = np.zeros(10)\n",
    "false_positive = np.zeros(10)\n",
    "false_negative = np.zeros(10)\n",
    "accuracy = 0\n",
    "ctn = 0\n",
    "for X, y in iter(test_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X).max(dim=1)[1]\n",
    "    for i in range(10):\n",
    "        for pred, real in zip(y_pred, y):\n",
    "            if real == i:\n",
    "                if pred == real:\n",
    "                    true_positive[i] += 1\n",
    "                else:\n",
    "                    false_negative[i] += 1\n",
    "            else:\n",
    "                if pred == i:\n",
    "                    false_positive[i] += 1\n",
    "                else:\n",
    "                    true_negative[i] += 1\n",
    "            \n",
    "    accuracy += torch.sum(y_pred == y).item()\n",
    "    ctn += len(y)\n",
    "print(\"Overall accuracy\", accuracy / ctn)\n",
    "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
    "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
    "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
    "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKA-j4rIQuvv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw05_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
